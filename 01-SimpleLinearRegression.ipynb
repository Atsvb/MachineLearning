{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Pandas to work with dataframes and numpy to do the math."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For linear regression we'll have a set of samples, each sample consists of a feature x_i and a label y_i. Linear regression will determine the weights  $w_0$ (intercept) and $w_1$ (the slope), to estimate a linear relation between the feature vector ($X$) and the label vector ($Y$). The estimate will be denoted $\\hat Y$.\n",
    "\n",
    "Pointwise:\n",
    "\n",
    "$${\\hat y}_i=x_0+w_1x_i$$\n",
    "\n",
    "And in vector form:\n",
    "$${\\hat Y}=w_0+w_1 \\cdot X$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the prediction of the linear model giventhe wights and the input feature\n",
    "def predictions_linear_reg(X, w_0, w_1):\n",
    "    pred=w_0+w_1*X\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Mean Squared Error as cost measure. The formula is:\n",
    "\n",
    "$$ mse=\\frac{\\sum_i^m(y_i-\\hat{y}_i)^2}{m}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute MSE\n",
    "def get_mse(X, Y, w_0,w_1):\n",
    "    #X is the feature vector (m,1)\n",
    "    #Y is the labels vector (m,1)\n",
    "    m=X.shape[0]\n",
    "    pred=predictions_linear_reg(X, w_0, w_1)\n",
    "    res=pred-Y\n",
    "    sqrd=res**2\n",
    "    MSE=np.sum(sqrd)/m\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we write the linear regression algorithm. Since we are working with one variable, it is not difficult to obtain the exact formula for $w_0$ and $w_1$ that minimizes the MSE (all sums are from $1$ to $m$):\n",
    "\n",
    "$$w_1=\\frac{\\sum x_iy_i - \\frac{\\sum x_i \\sum y_i}{m} }{\\sum x_i^2 - \\frac{(\\sum x_i)^2}{m}}$$\n",
    "\n",
    "$$w_0= \\sum y_i - w_1 \\frac{x_i}{m}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## simple linear regression with exact formula\n",
    "def linear_regression_simple_exact_formula(X, Y):\n",
    "    m=Y.size\n",
    "    sum_x=np.sum(X)\n",
    "    sum_y=np.sum(Y)\n",
    "    prod=X*Y\n",
    "    sum_prod=np.sum(prod)\n",
    "    sq_x=X*X\n",
    "    sum_sq_x=np.sum(sq_x)\n",
    "    sq_sum_x=sum_x**2\n",
    "    prod_sum_x_y=sum_x*sum_y\n",
    "    w_1=(sum_prod -prod_sum_x_y/m)/(sum_sq_x-sq_sum_x/m)\n",
    "    w_0=(sum_y- w_1*sum_x)/m\n",
    "    return w_0,w_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test this algorithm we are going to create a sample set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we generate a random list of 10 numbers uniformily distribuited\n",
    "X=np.random.uniform(0,1,[10,1])*100\n",
    "print(\"The feature vector is: \")\n",
    "print(X)\n",
    "#Then we create the Y vector applying a linear function to X\n",
    "Y=3*X+7\n",
    "print(\"This is the image of X when we apply a linear function: \")\n",
    "print(Y)\n",
    "#Finally we add some noise to Y\n",
    "for i in range(len(Y)):\n",
    "    Y[i]+=np.random.uniform(-5,5)\n",
    "print(\"The label (or output) vector is: \")    \n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply our algorithm to this set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_0, wa_1 =linear_regression_simple_exact_formula(X, Y)\n",
    "print(\"wa_0: \"+str(wa_0))\n",
    "print(\"wa_1: \"+str(wa_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE=get_mse(X,Y,wa_0,wa_1)\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will plot the sample points and the line obtained by the regression algorithm. We will use matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X,Y)\n",
    "t = np.arange(0.0, np.max(X), 0.01)\n",
    "plt.plot(t,wa_1*t+wa_0,'-',color='r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We procede now to write the gradient descent algorithm. We need to calculate the derivative of the MSE, with respect to the weights $w_0,w_1$:\n",
    "\n",
    "$$\\frac{d}{dw_0}mse=-\\frac{2}{m}\\sum(y_i-\\hat{y}_i)$$\n",
    "\n",
    "$$\\frac{d}{dw_1}mse=-\\frac{2}{m}\\sum x_i(y_i-\\hat{y}_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(X,Y,w_0,w_1):\n",
    "    m=X.shape[0]\n",
    "    error=Y- predictions_linear_reg(X, w_0,w_1)\n",
    "    dw_0=-2*np.sum(error)/m\n",
    "    dw_1=-2*np.sum(X*error )/m\n",
    "    return dw_0, dw_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that in this case we shall usa an hyperparameter: the learning rate.\n",
    "We update the weights as follows:\n",
    "\n",
    "$$w_j:=w_j- \\eta \\frac{d}{dw_j} mse$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_(X, Y, learning_rate, tolerance, initial_w_0, initial_w_1,max_iter=5000):\n",
    "    #X is the feature matrix\n",
    "    #Y is the output vector\n",
    "\n",
    "    w_0=initial_w_0\n",
    "    w_1=initial_w_1\n",
    "    converged = False\n",
    "    k=0\n",
    "    #We print the current iteration every 1000 iterations\n",
    "    while k<max_iter and not converged:\n",
    "        if k % 1000 == 0:\n",
    "            print(\"Iteration: \"+str(k))\n",
    "        preds=predictions_linear_reg(X, w_0,w_1)\n",
    "        error=Y-preds\n",
    "        dw_0,dw_1=derivative(X,Y, w_0,w_1)\n",
    "        w_0=w_0- learning_rate*dw_0\n",
    "        w_1=w_1-learning_rate*dw_1\n",
    "        gradient_norm=np.linalg.norm([dw_0,dw_1])\n",
    "        k=k+1\n",
    "        if gradient_norm < tolerance:\n",
    "            converged= True\n",
    "            print(\"Converged on iteration: \"+str(k))\n",
    "   \n",
    "    return w_0,w_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will apply this algorithm to the set we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.0001\n",
    "tolerance=.5\n",
    "initial_weights=[1.,1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_0,wb_1= gradient_descent_(X, Y, learning_rate, tolerance, initial_weights[0], initial_weights[1],max_iter=50000)\n",
    "print(\"wb_0: \"+str(wb_0))\n",
    "print(\"wb_1: \"+str(wb_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the MSE with these weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE=get_mse(X,Y,wb_0,wb_1)\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X,Y)\n",
    "t = np.arange(0.0, np.max(X), 0.01)\n",
    "plt.plot(t,wb_1*t+wb_0,'-',color='y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot both lines, the one obtained with the exact formula, and the one obtained with gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(0.0, np.max(X)/2, 0.01)\n",
    "plt.plot(t,wa_1*t+wa_0,'-',color='r')\n",
    "plt.plot(t,wb_1*t+wb_0,'-',color='y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if the error is bigger than the one obtained with the exact formula, and the weights are not quite the same, the line seems to aproximate the sample set pretty well.\n",
    "It is important to keep in mind that for the gradient descent algorithm we must chose the learning rate and the initial weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to use this algorithms on a \"real\" data set. We will import to our notebook a csv file with data of house prices. We will put this data on a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_prices=pd.read_csv(\"houseprices.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us explore the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_prices[[\"price\",\"LivingArea\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to split our data set on two parts: training set and validation set.We will do it in two new dataframes. We set a seed to the random process in order to make everythin repeatable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataframe into train and test sets\n",
    "def trainset__testset_split(df, train_ratio=.8, seed=0):\n",
    "    np.random.seed(seed)\n",
    "    m = len(df.index)\n",
    "    shuffle = np.random.permutation(df.index)\n",
    "    train_end = int(train_ratio * m)\n",
    "    train = df.loc[shuffle[:train_end]] \n",
    "    test = df.loc[shuffle[train_end:]]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's divide our set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set= trainset__testset_split(house_prices, train_ratio=.8, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the indexes are shuffled (that is what we did to create the random partition). So in order to locate the ith row of the train set we need to use the index vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The index corresponding to the fourth row is: \" +str(train_set.index[3]) )\n",
    "print(\"The fourth trow is: \"+ str(train_set.loc[train_set.index[0]]) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use \"LivingArea\" as feature and \"price\" as target label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_set['LivingArea']\n",
    "Y_train=train_set['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us apply the exact formula to the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_0,w_1=linear_regression_simple_exact_formula(X_train,Y_train)\n",
    "print(\"w_0 = \"+str(w_0))\n",
    "print(\"w_1 = \"+str(w_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the MSE for the training set, and we plot our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_train=get_mse(X_train,Y_train,w_0,w_1)\n",
    "print(np.format_float_scientific(MSE_train) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.plot(kind=\"scatter\", x=\"LivingArea\",y=\"price\")\n",
    "t = np.arange(0.0, 6000.0, 0.01)\n",
    "plt.plot(t,w_1*t+w_0,'-',color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to evaluate our model we must see how it does on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=test_set[\"LivingArea\"]\n",
    "Y_test=test_set[\"price\"]\n",
    "MSE_test=get_mse(X_test,Y_test,w_0,w_1)\n",
    "print(np.format_float_scientific(MSE_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.format_float_scientific(MSE_test-MSE_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us apply gradient descent. First we must set the hyperparameters: the initial weights, the tolerance and the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = np.array([15000., 10.])\n",
    "learning_rate = 1e-10\n",
    "tolerance = 1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_gd_0,w_gd_1=gradient_descent_(X_train,Y_train, learning_rate, tolerance, initial_weights[0], initial_weights[1],max_iter=200000)\n",
    "print(\"w_0 = \"+str(w_gd_0))\n",
    "print(\"w_1 = \"+str(w_gd_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the cost for these weights and the difference with the ones we obtained with the exact formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_train_gradient_desc=get_mse(X_train,Y_train,w_gd_0,w_gd_1)\n",
    "print(np.format_float_scientific(MSE_train_gradient_desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.format_float_scientific(MSE_train_gradient_desc-MSE_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we calculate the predictions of a data sample, to see how the algorithms do in a particular case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Prediction with the exact formula: \"+str(predictions_linear_reg(X_train[10], w_0, w_1)))\n",
    "print(\"Prediction with gradient descent: \"+str(predictions_linear_reg(X_train[10],w_gd_0,w_gd_1)))\n",
    "print(\"Actual value: \"+str(Y_train[10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the line obtained with gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.plot(kind=\"scatter\", x=\"LivingArea\",y=\"price\")\n",
    "t = np.arange(0.0, 6000.0, 0.01)\n",
    "plt.plot(t,w_1*t+w_0,'-',color='r')\n",
    "plt.plot(t,w_gd_1*t+w_gd_0,'-',color='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSE of the test set for the Gradient Descent model\n",
    "MSE_test_gradient_desdent=get_mse(X_test,Y_test,w_gd_0,w_gd_1)\n",
    "print(np.format_float_scientific(MSE_test_gradient_desdent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Difference bewtween the exact formula MSE and the gradient descent MSE for the test set\n",
    "print(np.format_float_scientific(MSE_test_gradient_desdent-MSE_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot of the lines and the test set\n",
    "test_set.plot(kind=\"scatter\", x=\"LivingArea\",y=\"price\")\n",
    "t = np.arange(0.0, 6000.0, 0.01)\n",
    "plt.plot(t,w_1*t+w_0,'-',color='r')\n",
    "plt.plot(t,w_gd_1*t+w_gd_0,'-',color='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot of both models\n",
    "t = np.arange(0.0, 1000.0, 0.01)\n",
    "plt.plot(t,w_1*t+w_0,'-',color='r')\n",
    "plt.plot(t,w_gd_1*t+w_gd_0,'-',color='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course we can chose a different feature (as long as it is \"numeric\") and apply our algorithms. Let's do it with \"Bedrooms\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2=train_set['Bedrooms']\n",
    "#Y is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with the exact formula:\n",
    "w_0,w_1=linear_regression_simple_exact_formula(X_train2,Y_train)\n",
    "print(\"w_0 = \"+str(w_0))\n",
    "print(\"w_1 = \"+str(w_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_train=get_mse(X_train2,Y_train,w_0,w_1)\n",
    "print(np.format_float_scientific(MSE_train) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.plot(kind=\"scatter\", x=\"Bedrooms\",y=\"price\")\n",
    "t = np.arange(0.0, 8.0, 0.01)\n",
    "plt.plot(t,w_1*t+w_0,'-',color='r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does not look right, it could be that \"Bedrooms\" is not a good feature to predict the price. Anyway, let's se what happens on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2=test_set[\"Bedrooms\"]\n",
    "MSE_test=get_mse(X_test2,Y_test,w_0,w_1)\n",
    "print(np.format_float_scientific(MSE_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.format_float_scientific(MSE_test-MSE_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = np.array([20000., 20000.])\n",
    "learning_rate = 1e-4\n",
    "tolerance = 1e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_gd_0,w_gd_1=gradient_descent_(X_train,Y_train, learning_rate, tolerance, initial_weights[0], initial_weights[1],max_iter=200000)\n",
    "print(\"w_0 = \"+str(w_gd_0))\n",
    "print(\"w_1 = \"+str(w_gd_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the cost and plot the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_train_gd=get_mse(X_train2,Y_train,w_gd_0,w_gd_1)\n",
    "print(np.format_float_scientific(MSE_train_gd) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.plot(kind=\"scatter\", x=\"Bedrooms\",y=\"price\")\n",
    "t = np.arange(0.0, 8.0, 0.01)\n",
    "plt.plot(t,w_gd_1*t+w_gd_0,'-',color='y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the cost for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_test_gd=get_mse(X_test2,Y_test,w_gd_0,w_gd_1)\n",
    "print(np.format_float_scientific(MSE_test_gd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the two models and the whole data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_prices.plot(kind=\"scatter\", x=\"Bedrooms\",y=\"price\")\n",
    "t = np.arange(0.0, 8.0, 0.01)\n",
    "plt.plot(t,w_1*t+w_0,'-',color='r')\n",
    "plt.plot(t,w_gd_1*t+w_gd_0,'-',color='y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
